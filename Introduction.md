Introduction
Namita Mishra
Diabetes mellitus (DM) is a major public health concern. Identifying risk factors associated with DM (obesity, age, race, and gender) and targeted interventions for prevention is crucial. Logistic Regression estimates the association between risk factors and binary outcomes (presence or absence of diabetes). However, classical maximum likelihood estimation (MLE) yields unstable results in small samples with missing data, or quasi- and complete separation.  Standard analytical approaches are insufficient in analyzing the complexity of healthcare data (DNA sequences, imaging, patient-reported outcomes, electronic health records (EHRs), longitudinal health measurements, diagnoses, and treatments. (Zeger et al., 2020)
The Bayesian hierarchical model with Markov Chain Monte Carlo (MCMC) has been implemented on multivariate longitudinal healthcare data by integrating prior knowledge to predict patient health status (Zeger et al., 2020). Model with two levels of data structure: (1) repeated measures over time within individuals and (2) individuals nested within a population, with added exogenous covariates (e.g., age, clinical history), and endogenous covariates (e.g., current treatment), yield posterior distributions of parameters. MCMC estimation provides marginal distributions of the regression coefficients in risk prediction (pneumonia, prostate cancer, and mental disorders). The model's limitation is its parametric nature, suggesting nonparametric or more flexible parametric models.
Application of **Bayesian Inference** @Chatzimichail2023, comparing parametric (with a fixed set of parameters) and non-parametric distributions (which do not make a priori assumptions) on National Health and Nutrition Examination Survey data from two separate diagnostic tests on both diseased and non-diseased populations, and provides posterior probability classifying diseases. Conventional methods based on clinical criteria and fixed numerical thresholds fail to capture the intricate relationship between diagnostic tests and the prevalence of the diseases; the dichotomous method (overlap of probability distributions between the diseased and nondiseased groups) fails to capture the complexity and heterogeneity across diverse populations. Its applicability in dealing with skewness, bimodality, or multimodality is critiqued. Integration of priors, combined with data from multiple diagnostic tests, improves diagnostic accuracy and precision. Bayesian nonparametric (vs parametric) is a flexible, adaptable, versatile, and robust approach, capturing complex data patterns, producing multimodal probability patterns vs the bimodal, double-sigmoidal curves in parametric models. Limited scholarly publications and over-dependence on priors limit model applicability. When combined with other statistical and computational techniques, it enhances diagnostic capabilities @Chatzimichail2023 in situations with systemic bias, unrepresentative, incomplete, and non-normal datasets. **Bayesian methodology** explained by @VandeSchoot2021 emphasizes the importance of priors, data modeling, inferences, model checking, sampling techniques from a posterior distribution, variational inferences, and variable selection for applicability across varied research fields (social sciences, ecology, genetics, and medicine). The variable selection is emphasized because multicollinearity, insufficient sampling, and overfitting result in poor predictive performance and difficult interpretation difficult. 
Prior types (informative, weakly informative, and diffuse) are based on the degree of (un)certainty (hyperparameters) surrounding the population parameter; a larger variance represents greater uncertainty; a mildly informative prior analyzes small sample sizes. Using both prior elicitation methods (experts, generic experts, data-based, and sample data using maximum likelihood or sample statistics), and prior sensitivity analysis of the likelihood assesses how the priors and the likelihood align. Prior provides data-informed shrinkage, regularization, or influence algorithms, providing a high-density region, improving estimation. Specification of the priors, in small and less informative samples, strengthens the observed data to lend possible value(s) for the unknown parameter(s). With unknown parameters having varied values, observed data having fixed values, and the likelihood function generating a range of possible values, integrating the MCMC algorithm for sampled values from a given distribution through computer simulations provides empirical estimates of the posterior distribution (BRMS and Blavaan in R). The frequentist method does not consider the probability of the unknown parameters and considers them as fixed, while likelihood is based on the conditional probability distribution p(y\|θ) of the data (y), given fixed parameters (θ). Spatial and temporal variability factored into Bayesian models has varied applicability (large-scale cancer genomic data, identifying novel molecular-level changes, interactions between mutated genes, capturing mutational signatures, allowing genomic-based patient stratification (clinical trials, personalized use of therapeutics), and understanding cancer evolutionary processes). The Bayesian model is reproducible, but autocorrelation in the temporal model and subjectivity issues in prior elicitation are limitations. 
Prior elicitation, analytical posteriors, robustness checks in **Bayesian Normal linear regression, and parametric (conjugate) model incorporating Normal–Inverse-Gamma prior** have been demonstrated in metrology @Klauenberg2015 to calibrate instruments. In Gaussian, errors are independent and identically distributed, the variance is unknown, the relationship between X and Y is statistical, with noise and model uncertainty, and the regression can not be treated as a measurement function. Methods like Likelihood, Bayesian, bootstrap, etc., quantify uncertainty, account for a priori information, and robustify analyses through prior elicitation and posterior calculation. Observables (data) and unobservables (parameters and auxiliary variables) are unknown and random, and the assigned probability distributions update prior knowledge about the unobservables, enhancing the elicitation and interpretation process. Normal Inverse Gamma (NIG) distribution to a posterior is from the same family of (NIG) prior distribution, and the known variance (conjugate prior) can drive vague or non-informative prior distributions (2). An alternative (hierarchical) prior provides an additional layer of distributions to uncertainty. 
**Bayesian Hierarchical / meta-analytic linear regression** model @DeLeeuw2012 augments data incorporating both exchangeable and unexchangeable information on regression coefficients (and standard errors) from previous studies, addressing multiple testing associated with low statistical power, issues of conducting separate significance tests for all regression coefficients in modest sample sizes across studies with different predictors, and the need for larger samples. Linear regression does not incorporate priors, produce smaller estimates that are unreliable and vulnerable to sample variations.
In situations where previous studies are unavailable, priors from meta-analysis in Bayesian regression address the challenge of large sample size, supplementing and resolving the limitations of univariate analyses that overlook the relationships among multiple regression parameters within a study. With prior specifications from both prior data and current data, priors are categorized as: (1) Exchangeable when the current data and previous studies share the same set of predictors, and (2) Unexchangeable when the predictors differ across studies. (1) The probability density function for the data (using the Gibbs sampler), and (2) the likelihood function reflect prior assumptions about the model parameters before observing the data. The hierarchical unexchangeable model is applicable in studying differences in studies, enabling explicit testing of the exchangeability assumption, but the applicability is limited to the correlation issue of having identical set of predictors. (DeLeeuw, 2012).
Bayesian logistic regression (Bayesian GLM)**- A sequential clinical reasoning was applicable in screening adults (20–79 years, Taiwan), to classify incident cancers and cardiovascular disease. Three models with sequential adding of predictors: (1) demographic features (basic model), (2) six metabolic syndrome components (metabolic score model), and (3) conventional risk factors (enhanced model), and by incorporating priors, Liu (2013) demonstrated the model could address the limited availability of molecular information and is an alternative method leveraging routinely collected biological markers for classification of diseases. In contrast, the Framingham Risk Score is limited by geographic, ethnic, and social contextual heterogeneity across populations. Emulates a clinician’s evaluation process, the model assumes normally distributed regression coefficients, accounts for uncertainty in clinical weights, and averages credible intervals for predicted risk estimates. By updating prior clinical expectations with objective observed data (patient history and laboratory findings), the posterior distributions produced (Enhanced model) showed that patient background significantly contributed to baseline risk estimation by integrating individual characteristics that capture ecological heterogeneity. The model limitations are the potential interactions between predictors and external cross-validation.
Bayesian multiple imputation with logistic regression, @Austin 2021, addresses missing data in clinical research. Analyzing reasons of missing values (i) patients refusing to answer specific questions, (ii) loss to follow-up, (iii) investigator or mechanical errors, or (iv) physicians choosing not to order certain investigations require understanding of the type of missingness: missing at random (MAR), missing not at random (MNAR), or missing completely at random (MCAR) and addressing missingness by multiple imputation (MI) ( R, SAS, or Stata) classify patients with heart failure and provide estimates of 1-year mortality. Plausible values are generated by MI, creating multiple completed datasets while simultaneously conducting identical statistical analyses across them, providing robust estimates through pooled results.
Aims
The present study focuses on the application of Bayesian logistic regression to predict diabetes status based on body mass index (BMI), age, gender, and race as predictors using a retrospective dataset (2013–2014 NHANES survey). The dataset reveals challenges such as quasi-separation, missing values, and a relatively small effective sample size, and the traditional logistic regression has limitations in dealing with these anomalies. Initial data exploration yielded 9,813 observations across five selected variables. The results from complete case analysis, listwise deletion, substantially reduced the sample size to only 14 complete cases and presented quasi-separation with implausibly large coefficients and unstable estimates. The analytic limitations of traditional logistic regression motivate us to perform Multiple Imputation by Chained Equations (MICE) in conjunction with Bayesian logistic regression. The approach could provide a flexible framework for modeling uncertainty, incorporating prior knowledge, and addressing issues related to quasi-separation and limited sample size.
______________________________________________________________________________
Autumn Wilcox
Bayesian reasoning provides a powerful alternative to traditional statistical methods when analyzing complex or uncertain health data. Although it is often portrayed as overly technical, work by Kruschke and Liddell (2017) emphasizes that Bayesian thinking is intuitive and reflects how individuals update beliefs as new information becomes available. Their introduction to priors, likelihoods, and posteriors highlights that these elements provide a natural and accessible way to represent uncertainty, laying the groundwork for applying Bayesian analysis in healthcare research.
Applications of Bayesian regression highlight its advantages in clinical contexts where small sample sizes, noisy data, and prior knowledge are important. For example, Baldwin and Larson (2017) demonstrate the use of Bayesian linear regression with EEG and anxiety data, showing how priors can be specified, models fitted in R and Stan, and posterior distributions interpreted. Their tutorial illustrates that Bayesian models not only yield results comparable to frequentist regression but also provide richer probabilistic interpretations, such as estimating the probability that a parameter exceeds a clinically meaningful threshold. Similar tutorials reinforce the importance of convergence checks and transparency when applying Bayesian regression in practice (Baldwin & Larson, 2017).
The literature also extends into Bayesian deep learning, where probabilistic reasoning is combined with the flexibility of neural networks. Abdullah, Hassan, and Mustafa (2022) provide a comprehensive review of Bayesian deep learning applications in healthcare, showing how these models improve uncertainty quantification and support clinical decision-making in tasks such as medical imaging, disease classification, and survival analysis. At the same time, they note challenges including computational expense, difficulties in specifying priors, and barriers to translation into real-world practice.
Across these works, a consistent theme emerges: Bayesian approaches allow researchers to incorporate prior knowledge, quantify uncertainty, and generate results that are both more interpretable and more aligned with the realities of clinical data (Kruschke & Liddell, 2017; Baldwin & Larson, 2017; Abdullah et al., 2022). At the same time, challenges of computation, subjective prior choice, and limited practitioner training remain obstacles to widespread adoption. Collectively, this body of literature reinforces the importance of Bayesian methods as a flexible framework for analyzing health data. The emphasis on uncertainty and interpretability directly supports the motivation for our project, which applies Bayesian logistic regression to NHANES survey data in order to explore predictors of diabetes outcomes while addressing missing data and the limitations of classical models.


References (APA, 7th edition)
 Zeger, S. L., Wu, Z., Coley, Y., Fojo, A. T., Carter, B., O’Brien, K., Zandi, P., Cooke, M., Carey, V., Crainiceanu, C., Muscelli, J., Gherman, A., & Mekosh, J. (2020). Using a Bayesian Approach to Predict Patients’ Health and Response to Treatment. 2020.
Chatzimichail, T., & Hatjimihail, A. T. (2023). A Bayesian Inference-Based Computational Tool for Parametric and Nonparametric Medical Diagnosis. Diagnostics, 13(19). https://doi.org/10.3390/DIAGNOSTICS13193135,
Klauenberg, K., Wübbeler, G., Mickan, B., Harris, P., & Elster, C. (2015). A tutorial on Bayesian Normal linear regression. Metrologia, 52(6), 878–892. https://doi.org/10.1088/0026-1394/52/6/878
de Leeuw, C., & Klugkist, I. (2012). Augmenting Data With Published Results in Bayesian Linear Regression. Multivariate Behavioral Research, 47(3), 369–391. https://doi.org/10.1080/00273171.2012.673957
Liu, Y. M., Chen, S. L. S., Yen, A. M. F., & Chen, H. H. (2013). Individual risk prediction model for incident cardiovascular disease: A Bayesian clinical reasoning approach. International Journal of Cardiology, 167(5), 2008–2012. https://doi.org/10.1016/J
Austin, P. C., White, I. R., Lee, D. S., & van Buuren, S. (2021). Missing Data in Clinical Research: A Tutorial on Multiple Imputation. Canadian Journal of Cardiology, 37(9), 1322–1331. https://doi.org/10.1016/j.cjca.2020.11.010
Abdullah, M., Hassan, R., & Mustafa, M. (2022). A review on Bayesian deep learning in healthcare: Applications and challenges. IEEE Access, 10, 36538–36562. https://doi.org/10.1109/ACCESS.2022.3157141
Baldwin, S. A., & Larson, M. J. (2017). An introduction to using Bayesian linear regression with clinical data. Behaviour Research and Therapy, 98, 58–75. https://doi.org/10.1016/j.brat.2017.05.014
Kruschke, J. K., & Liddell, T. M. (2017). Bayesian data analysis for newcomers. Psychonomic Bulletin & Review, 25(1), 155–177. https://doi.org/10.3758/s13423-017-1272-1

